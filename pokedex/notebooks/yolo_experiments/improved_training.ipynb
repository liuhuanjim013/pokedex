{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "{\n",
        " \"cells\": [\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"# YOLOv3 Improved Training (Enhanced Parameters)\\n\",\n",
        "    \"\\n\",\n",
        "    \"This notebook implements enhanced YOLOv3 training to address the original blog's limitations.\\n\",\n",
        "    \"\\n\",\n",
        "    \"## Overview\\n\",\n",
        "    \"\\n\",\n",
        "    \"**Goal**: Improve upon baseline with enhanced training parameters.\\n\",\n",
        "    \"\\n\",\n",
        "    \"**Dataset**: `liuhuanjim013/pokemon-yolo-1025` (1025 classes)\\n\",\n",
        "    \"\\n\",\n",
        "    \"**Improvements**:\\n\",\n",
        "    \"- Enhanced augmentation (rotation, shear, mosaic, mixup)\\n\",\n",
        "    \"- Cosine learning rate scheduling with warmup\\n\",\n",
        "    \"- Early stopping to prevent overfitting\\n\",\n",
        "    \"- Larger batch size (32 vs 16)\\n\",\n",
        "    \"- Longer training (200 epochs vs 100)\\n\",\n",
        "    \"- Better regularization techniques\\n\",\n",
        "    \"\\n\",\n",
        "    \"## Requirements\\n\",\n",
        "    \"- Google Colab with GPU runtime\\n\",\n",
        "    \"- Google Drive mounted for checkpoint storage\\n\",\n",
        "    \"- Weights & Biases account (free)\\n\",\n",
        "    \"- Hugging Face account for dataset access\\n\",\n",
        "    \"\\n\",\n",
        "    \"## Usage\\n\",\n",
        "    \"1. Run cells sequentially\\n\",\n",
        "    \"2. Monitor training in W&B dashboard\\n\",\n",
        "    \"3. Checkpoints saved to Drive automatically\\n\",\n",
        "    \"4. Can resume from latest checkpoint if interrupted\\n\",\n",
        "    \"\\n\",\n",
        "    \"## Expected Improvements\\n\",\n",
        "    \"- Better performance in varying lighting conditions\\n\",\n",
        "    \"- Reduced sensitivity to object size and background\\n\",\n",
        "    \"- Higher overall recognition accuracy\\n\",\n",
        "    \"- More robust real-world performance\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## 1. Environment & Resource Setup\\n\",\n",
        "    \"\\n\",\n",
        "    \"### 1.1 Mount Google Drive\\n\",\n",
        "    \"First, we'll mount Google Drive for persistent storage of checkpoints and logs.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Mount Google Drive for checkpoint persistence\\n\",\n",
        "    \"try:\\n\",\n",
        "    \"    from google.colab import drive\\n\",\n",
        "    \"    drive.mount('/content/drive')\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    # Create directories for checkpoints and logs\\n\",\n",
        "    \"    import os\\n\",\n",
        "    \"    checkpoint_dir = '/content/drive/MyDrive/pokemon_yolo/checkpoints/improved'\\n\",\n",
        "    \"    log_dir = '/content/drive/MyDrive/pokemon_yolo/logs/improved'\\n\",\n",
        "    \"    os.makedirs(checkpoint_dir, exist_ok=True)\\n\",\n",
        "    \"    os.makedirs(log_dir, exist_ok=True)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    print(\\\"‚úÖ Google Drive mounted successfully!\\\")\\n\",\n",
        "    \"    print(f\\\"üìÅ Checkpoint directory: {checkpoint_dir}\\\")\\n\",\n",
        "    \"    print(f\\\"üìÅ Log directory: {log_dir}\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"except Exception as e:\\n\",\n",
        "    \"    print(f\\\"‚ùå Failed to mount Google Drive: {e}\\\")\\n\",\n",
        "    \"    raise  # Re-raise to stop execution\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"### 1.2 Clone Repository & Set Up Environment\\n\",\n",
        "    \"Now we'll clone the repository and set up the environment using our centralized setup script.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Clone repository if not already present\\n\",\n",
        "    \"import os\\n\",\n",
        "    \"if not os.path.exists('/content/pokedex'):\\n\",\n",
        "    \"    !git clone https://github.com/your-repo/pokedex.git /content/pokedex\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Change to repository directory\\n\",\n",
        "    \"%cd /content/pokedex\\n\",\n",
        "    \"\\n\",\n",
        "    \"try:\\n\",\n",
        "    \"    # Use centralized environment setup script\\n\",\n",
        "    \"    !python scripts/common/setup_environment.py --experiment yolo --colab --verify\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    print(\\\"\\\\n‚úÖ Environment setup completed!\\\")\\n\",\n",
        "    \"    print(\\\"Using centralized setup script for consistency with local development.\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"except Exception as e:\\n\",\n",
        "    \"    print(f\\\"‚ùå Environment setup failed: {e}\\\")\\n\",\n",
        "    \"    raise  # Re-raise to stop execution\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"### 1.3 Verify GPU & Dependencies\\n\",\n",
        "    \"Let's verify that we have GPU access and all required dependencies are installed correctly.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Verify GPU availability\\n\",\n",
        "    \"import torch\\n\",\n",
        "    \"import sys\\n\",\n",
        "    \"\\n\",\n",
        "    \"try:\\n\",\n",
        "    \"    # Check GPU\\n\",\n",
        "    \"    if not torch.cuda.is_available():\\n\",\n",
        "    \"        raise RuntimeError(\\\"No GPU available! Please enable GPU runtime in Colab.\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    print(\\\"üéØ System Check:\\\")\\n\",\n",
        "    \"    print(f\\\"‚Ä¢ Python version: {sys.version.split()[0]}\\\")\\n\",\n",
        "    \"    print(f\\\"‚Ä¢ PyTorch version: {torch.__version__}\\\")\\n\",\n",
        "    \"    print(f\\\"‚Ä¢ GPU available: {torch.cuda.get_device_name(0)}\\\")\\n\",\n",
        "    \"    print(f\\\"‚Ä¢ CUDA version: {torch.version.cuda}\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    # Import and verify key dependencies\\n\",\n",
        "    \"    import wandb\\n\",\n",
        "    \"    from ultralytics import YOLO\\n\",\n",
        "    \"    from datasets import load_dataset\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    print(\\\"\\\\nüì¶ Key Dependencies:\\\")\\n\",\n",
        "    \"    print(f\\\"‚Ä¢ Weights & Biases: {wandb.__version__}\\\")\\n\",\n",
        "    \"    print(f\\\"‚Ä¢ Ultralytics: {YOLO.__version__}\\\")\\n\",\n",
        "    \"    print(f\\\"‚Ä¢ Hugging Face Datasets: {datasets.__version__}\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    print(\\\"\\\\n‚úÖ All dependencies verified successfully!\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"except Exception as e:\\n\",\n",
        "    \"    print(f\\\"‚ùå Dependency verification failed: {e}\\\")\\n\",\n",
        "    \"    raise  # Re-raise to stop execution\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"### 1.4 Initialize W&B\\n\",\n",
        "    \"Set up Weights & Biases for experiment tracking. We'll use the same project and entity as our local training.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Initialize W&B with same project/entity as local training\\n\",\n",
        "    \"import wandb\\n\",\n",
        "    \"import yaml\\n\",\n",
        "    \"from pathlib import Path\\n\",\n",
        "    \"\\n\",\n",
        "    \"try:\\n\",\n",
        "    \"    # Load W&B configuration from improved config\\n\",\n",
        "    \"    config_path = Path(\\\"configs/yolov3/improved_config.yaml\\\")\\n\",\n",
        "    \"    with open(config_path) as f:\\n\",\n",
        "    \"        config = yaml.safe_load(f)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    # Initialize W&B run\\n\",\n",
        "    \"    wandb.init(\\n\",\n",
        "    \"        project=config['wandb']['project'],\\n\",\n",
        "    \"        name=config['wandb']['name'],\\n\",\n",
        "    \"        entity=config['wandb']['entity'],\\n\",\n",
        "    \"        tags=config['wandb']['tags'],\\n\",\n",
        "    \"        config=config,\\n\",\n",
        "    \"        resume=True  # Enable run resumption\\n\",\n",
        "    \"    )\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    print(\\\"‚úÖ W&B initialized successfully!\\\")\\n\",\n",
        "    \"    print(f\\\"üìä Dashboard: https://wandb.ai/{config['wandb']['entity']}/{config['wandb']['project']}\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"except Exception as e:\\n\",\n",
        "    \"    print(f\\\"‚ùå W&B initialization failed: {e}\\\")\\n\",\n",
        "    \"    raise  # Re-raise to stop execution\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## 2. Training Preparation\\n\",\n",
        "    \"\\n\",\n",
        "    \"### 2.1 Import Source Modules\\n\",\n",
        "    \"Import our reusable source modules, consistent with how they're used in production scripts.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Add src to path for module imports (same as scripts)\\n\",\n",
        "    \"import sys\\n\",\n",
        "    \"import os\\n\",\n",
        "    \"sys.path.append('/content/pokedex/src')  # For Colab\\n\",\n",
        "    \"\\n\",\n",
        "    \"try:\\n\",\n",
        "    \"    # Import reusable source modules (same as scripts)\\n\",\n",
        "    \"    from training.yolo.trainer import YOLOTrainer\\n\",\n",
        "    \"    from evaluation.yolo.evaluator import YOLOEvaluator\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    print(\\\"‚úÖ Source modules imported successfully!\\\")\\n\",\n",
        "    \"    print(\\\"Using same modular architecture as production scripts.\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"except Exception as e:\\n\",\n",
        "    \"    print(f\\\"‚ùå Module import failed: {e}\\\")\\n\",\n",
        "    \"    raise  # Re-raise to stop execution\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"### 2.2 Initialize Training\\n\",\n",
        "    \"Set up the trainer with improved configuration and check for existing checkpoints.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Initialize trainer with improved configuration\\n\",\n",
        "    \"try:\\n\",\n",
        "    \"    # Use same configuration as production scripts\\n\",\n",
        "    \"    config_path = \\\"configs/yolov3/improved_config.yaml\\\"\\n\",\n",
        "    \"    trainer = YOLOTrainer(config_path)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    # Check for existing checkpoints\\n\",\n",
        "    \"    start_epoch = 0\\n\",\n",
        "    \"    if os.path.exists(checkpoint_dir):\\n\",\n",
        "    \"        checkpoint_files = sorted(os.listdir(checkpoint_dir))\\n\",\n",
        "    \"        if checkpoint_files:\\n\",\n",
        "    \"            latest_checkpoint = os.path.join(checkpoint_dir, checkpoint_files[-1])\\n\",\n",
        "    \"            print(f\\\"\\\\nüì¶ Found checkpoint: {latest_checkpoint}\\\")\\n\",\n",
        "    \"            start_epoch = trainer.load_checkpoint()\\n\",\n",
        "    \"            print(f\\\"‚úÖ Resuming from epoch {start_epoch}\\\")\\n\",\n",
        "    \"        else:\\n\",\n",
        "    \"            print(\\\"\\\\nüìã No existing checkpoints found. Starting fresh training.\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    print(\\\"\\\\nüéØ Training Configuration:\\\")\\n\",\n",
        "    \"    print(f\\\"‚Ä¢ Config file: {config_path}\\\")\\n\",\n",
        "    \"    print(f\\\"‚Ä¢ Starting epoch: {start_epoch}\\\")\\n\",\n",
        "    \"    print(f\\\"‚Ä¢ Total epochs: {trainer.config['training']['epochs']}\\\")\\n\",\n",
        "    \"    print(f\\\"‚Ä¢ Batch size: {trainer.config['training']['batch_size']}\\\")\\n\",\n",
        "    \"    print(f\\\"‚Ä¢ Learning rate: {trainer.config['training']['learning_rate']}\\\")\\n\",\n",
        "    \"    print(f\\\"‚Ä¢ Checkpoint dir: {checkpoint_dir}\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    print(\\\"\\\\nüìà Improvements over baseline:\\\")\\n\",\n",
        "    \"    print(\\\"‚Ä¢ Enhanced augmentation (rotation, shear, mosaic, mixup)\\\")\\n\",\n",
        "    \"    print(\\\"‚Ä¢ Cosine learning rate scheduling with warmup\\\")\\n\",\n",
        "    \"    print(\\\"‚Ä¢ Early stopping (patience=10)\\\")\\n\",\n",
        "    \"    print(\\\"‚Ä¢ Larger batch size (32 vs 16)\\\")\\n\",\n",
        "    \"    print(\\\"‚Ä¢ Longer training (200 epochs vs 100)\\\")\\n\",\n",
        "    \"    print(\\\"‚Ä¢ Better regularization techniques\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"except Exception as e:\\n\",\n",
        "    \"    print(f\\\"‚ùå Training initialization failed: {e}\\\")\\n\",\n",
        "    \"    raise  # Re-raise to stop execution\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## 3. Training Execution\\n\",\n",
        "    \"\\n\",\n",
        "    \"### 3.1 Execute Training\\n\",\n",
        "    \"Run the improved training process with proper error handling and progress monitoring.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Execute improved training with checkpoint support\\n\",\n",
        "    \"print(\\\"üöÄ Starting improved training...\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"try:\\n\",\n",
        "    \"    # Start training from last checkpoint or beginning\\n\",\n",
        "    \"    results = trainer.train(start_epoch=start_epoch)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    print(\\\"\\\\n‚úÖ Training completed successfully!\\\")\\n\",\n",
        "    \"    print(\\\"\\\\nüìä Final Results:\\\")\\n\",\n",
        "    \"    for metric, value in results.items():\\n\",\n",
        "    \"        print(f\\\"‚Ä¢ {metric}: {value:.4f}\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    # Save final model to Drive\\n\",\n",
        "    \"    final_model_path = os.path.join(checkpoint_dir, \\\"yolov3_improved_final.pt\\\")\\n\",\n",
        "    \"    trainer.save_model(final_model_path)\\n\",\n",
        "    \"    print(f\\\"\\\\nüíæ Final model saved: {final_model_path}\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    # Log final artifacts to W&B\\n\",\n",
        "    \"    wandb.save(final_model_path)\\n\",\n",
        "    \"    print(\\\"\\\\nüì§ Model artifacts uploaded to W&B\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"except KeyboardInterrupt:\\n\",\n",
        "    \"    print(\\\"\\\\n‚ö†Ô∏è Training interrupted by user!\\\")\\n\",\n",
        "    \"    print(\\\"Latest checkpoint was saved automatically.\\\")\\n\",\n",
        "    \"    print(\\\"You can resume training by running this notebook again.\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"except Exception as e:\\n\",\n",
        "    \"    print(f\\\"\\\\n‚ùå Training failed: {e}\\\")\\n\",\n",
        "    \"    raise  # Re-raise to stop execution\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"### 3.2 Evaluate Model & Compare\\n\",\n",
        "    \"Run evaluation on the test set and compare with baseline results.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Evaluate improved model and compare with baseline\\n\",\n",
        "    \"try:\\n\",\n",
        "    \"    # Initialize evaluator\\n\",\n",
        "    \"    evaluator = YOLOEvaluator(trainer.model, trainer.config)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    # Run evaluation\\n\",\n",
        "    \"    test_data = \\\"liuhuanjim013/pokemon-yolo-1025\\\"\\n\",\n",
        "    \"    evaluation_results = evaluator.evaluate_model(test_data)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    print(\\\"\\\\nüìä Improved Model Evaluation Results:\\\")\\n\",\n",
        "    \"    for metric, value in evaluation_results.items():\\n\",\n",
        "    \"        print(f\\\"‚Ä¢ {metric}: {value:.4f}\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    # Log evaluation results to W&B\\n\",\n",
        "    \"    wandb.log({\\\"final_evaluation\\\": evaluation_results})\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    print(\\\"\\\\nüìà Improvements Over Baseline:\\\")\\n\",\n",
        "    \"    print(\\\"1. Enhanced Augmentation:\\\")\\n\",\n",
        "    \"    print(\\\"   ‚Ä¢ Added rotation (¬±10¬∞)\\\")\\n\",\n",
        "    \"    print(\\\"   ‚Ä¢ Added translation (¬±20%)\\\")\\n\",\n",
        "    \"    print(\\\"   ‚Ä¢ Added shear (¬±2¬∞)\\\")\\n\",\n",
        "    \"    print(\\\"   ‚Ä¢ Added mosaic (prob=1.0)\\\")\\n\",\n",
        "    \"    print(\\\"   ‚Ä¢ Added mixup (prob=0.1)\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    print(\\\"\\\\n2. Training Enhancements:\\\")\\n\",\n",
        "    \"    print(\\\"   ‚Ä¢ Cosine learning rate scheduling\\\")\\n\",\n",
        "    \"    print(\\\"   ‚Ä¢ 5 epochs warmup\\\")\\n\",\n",
        "    \"    print(\\\"   ‚Ä¢ Early stopping (patience=10)\\\")\\n\",\n",
        "    \"    print(\\\"   ‚Ä¢ Larger batch size (32)\\\")\\n\",\n",
        "    \"    print(\\\"   ‚Ä¢ Longer training (200 epochs)\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    print(\\\"\\\\n3. Expected Benefits:\\\")\\n\",\n",
        "    \"    print(\\\"   ‚Ä¢ Better handling of lighting variations\\\")\\n\",\n",
        "    \"    print(\\\"   ‚Ä¢ Improved size/scale robustness\\\")\\n\",\n",
        "    \"    print(\\\"   ‚Ä¢ Reduced background interference\\\")\\n\",\n",
        "    \"    print(\\\"   ‚Ä¢ Higher overall accuracy\\\")\\n\",\n",
        "    \"    print(\\\"   ‚Ä¢ Better generalization\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"except Exception as e:\\n\",\n",
        "    \"    print(f\\\"\\\\n‚ùå Evaluation failed: {e}\\\")\\n\",\n",
        "    \"    raise  # Re-raise to stop execution\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## 4. Cleanup & Next Steps\\n\",\n",
        "    \"\\n\",\n",
        "    \"### 4.1 Resource Cleanup\\n\",\n",
        "    \"Clean up resources and unmount Google Drive.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Clean up resources\\n\",\n",
        "    \"try:\\n\",\n",
        "    \"    # Finish W&B run\\n\",\n",
        "    \"    wandb.finish()\\n\",\n",
        "    \"    print(\\\"‚úÖ W&B run completed and synced\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    # Unmount Google Drive\\n\",\n",
        "    \"    from google.colab import drive\\n\",\n",
        "    \"    drive.flush_and_unmount()\\n\",\n",
        "    \"    print(\\\"‚úÖ Google Drive unmounted safely\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    print(\\\"\\\\nüéØ Next Steps:\\\")\\n\",\n",
        "    \"    print(\\\"1. Check W&B dashboard for training visualizations\\\")\\n\",\n",
        "    \"    print(\\\"2. Review saved checkpoints in Google Drive\\\")\\n\",\n",
        "    \"    print(\\\"3. Compare performance with baseline results\\\")\\n\",\n",
        "    \"    print(\\\"4. Consider further improvements based on results\\\")\\n\",\n",
        "    \"    print(\\\"\\\\n‚ú® Improved training completed successfully!\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"except Exception as e:\\n\",\n",
        "    \"    print(f\\\"‚ùå Cleanup failed: {e}\\\")\\n\",\n",
        "    \"    print(\\\"‚ö†Ô∏è Please manually unmount Google Drive and close W&B run\\\")\"\n",
        "   ]\n",
        "  }\n",
        " ],\n",
        " \"metadata\": {\n",
        "  \"kernelspec\": {\n",
        "   \"display_name\": \"Python 3\",\n",
        "   \"language\": \"python\",\n",
        "   \"name\": \"python3\"\n",
        "  },\n",
        "  \"language_info\": {\n",
        "   \"codemirror_mode\": {\n",
        "    \"name\": \"ipython\",\n",
        "    \"version\": 3\n",
        "   },\n",
        "   \"file_extension\": \".py\",\n",
        "   \"mimetype\": \"text/x-python\",\n",
        "   \"name\": \"python\",\n",
        "   \"nbconvert_exporter\": \"python\",\n",
        "   \"pygments_lexer\": \"ipython3\",\n",
        "   \"version\": \"3.9.0\"\n",
        "  }\n",
        " },\n",
        " \"nbformat\": 4,\n",
        " \"nbformat_minor\": 4\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# YOLOv3 Improved Training (Enhanced Parameters)\n",
        "\n",
        "This notebook implements enhanced YOLOv3 training to address the original blog's limitations.\n",
        "\n",
        "## Overview\n",
        "\n",
        "**Goal**: Improve upon baseline with enhanced training parameters.\n",
        "\n",
        "**Dataset**: `liuhuanjim013/pokemon-yolo-1025` (1025 classes)\n",
        "\n",
        "**Improvements**:\n",
        "- Enhanced augmentation (rotation, shear, mosaic, mixup)\n",
        "- Cosine learning rate scheduling with warmup\n",
        "- Early stopping to prevent overfitting\n",
        "- Larger batch size (32 vs 16)\n",
        "- Longer training (200 epochs vs 100)\n",
        "- Better regularization techniques\n",
        "\n",
        "## Requirements\n",
        "- Google Colab with GPU runtime\n",
        "- Google Drive mounted for checkpoint storage\n",
        "- Weights & Biases account (free)\n",
        "- Hugging Face account for dataset access\n",
        "\n",
        "## Usage\n",
        "1. Run cells sequentially\n",
        "2. Monitor training in W&B dashboard\n",
        "3. Checkpoints saved to Drive automatically\n",
        "4. Can resume from latest checkpoint if interrupted\n",
        "\n",
        "## Expected Improvements\n",
        "- Better performance in varying lighting conditions\n",
        "- Reduced sensitivity to object size and background\n",
        "- Higher overall recognition accuracy\n",
        "- More robust real-world performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# YOLOv3 Improved Training (Enhanced Parameters)\n",
        "\n",
        "This notebook implements enhanced YOLOv3 training to address the original blog's limitations.\n",
        "\n",
        "## Overview\n",
        "\n",
        "**Goal**: Improve upon baseline with enhanced training parameters.\n",
        "\n",
        "**Dataset**: `liuhuanjim013/pokemon-yolo-1025` (1025 classes)\n",
        "\n",
        "**Improvements**:\n",
        "- Enhanced augmentation (rotation, shear, mosaic, mixup)\n",
        "- Cosine learning rate scheduling with warmup\n",
        "- Early stopping to prevent overfitting\n",
        "- Larger batch size (32 vs 16)\n",
        "- Longer training (200 epochs vs 100)\n",
        "- Better regularization techniques\n",
        "\n",
        "## Requirements\n",
        "- Google Colab with GPU runtime\n",
        "- Google Drive mounted for checkpoint storage\n",
        "- Weights & Biases account (free)\n",
        "- Hugging Face account for dataset access\n",
        "\n",
        "## Usage\n",
        "1. Run cells sequentially\n",
        "2. Monitor training in W&B dashboard\n",
        "3. Checkpoints saved to Drive automatically\n",
        "4. Can resume from latest checkpoint if interrupted\n",
        "\n",
        "## Expected Improvements\n",
        "- Better performance in varying lighting conditions\n",
        "- Reduced sensitivity to object size and background\n",
        "- Higher overall recognition accuracy\n",
        "- More robust real-world performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 1. Environment & Resource Setup\n",
        "\n",
        "### 1.1 Mount Google Drive\n",
        "First, we'll mount Google Drive for persistent storage of checkpoints and logs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive for checkpoint persistence\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "    # Create directories for checkpoints and logs\n",
        "    import os\n",
        "    checkpoint_dir = '/content/drive/MyDrive/pokemon_yolo/checkpoints/improved'\n",
        "    log_dir = '/content/drive/MyDrive/pokemon_yolo/logs/improved'\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "    \n",
        "    print(\"‚úÖ Google Drive mounted successfully!\")\n",
        "    print(f\"üìÅ Checkpoint directory: {checkpoint_dir}\")\n",
        "    print(f\"üìÅ Log directory: {log_dir}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to mount Google Drive: {e}\")\n",
        "    raise  # Re-raise to stop execution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "### 1.2 Clone Repository & Set Up Environment\n",
        "Now we'll clone the repository and set up the environment using our centralized setup script.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository if not already present\n",
        "import os\n",
        "if not os.path.exists('/content/pokedex'):\n",
        "    !git clone https://github.com/your-repo/pokedex.git /content/pokedex\n",
        "\n",
        "# Change to repository directory\n",
        "%cd /content/pokedex\n",
        "\n",
        "try:\n",
        "    # Use centralized environment setup script\n",
        "    !python scripts/common/setup_environment.py --experiment yolo --colab --verify\n",
        "    \n",
        "    print(\"\\n‚úÖ Environment setup completed!\")\n",
        "    print(\"Using centralized setup script for consistency with local development.\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Environment setup failed: {e}\")\n",
        "    raise  # Re-raise to stop execution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "### 1.3 Verify GPU & Dependencies\n",
        "Let's verify that we have GPU access and all required dependencies are installed correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify GPU availability\n",
        "import torch\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    # Check GPU\n",
        "    if not torch.cuda.is_available():\n",
        "        raise RuntimeError(\"No GPU available! Please enable GPU runtime in Colab.\")\n",
        "    \n",
        "    print(\"üéØ System Check:\")\n",
        "    print(f\"‚Ä¢ Python version: {sys.version.split()[0]}\")\n",
        "    print(f\"‚Ä¢ PyTorch version: {torch.__version__}\")\n",
        "    print(f\"‚Ä¢ GPU available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"‚Ä¢ CUDA version: {torch.version.cuda}\")\n",
        "    \n",
        "    # Import and verify key dependencies\n",
        "    import wandb\n",
        "    from ultralytics import YOLO\n",
        "    from datasets import load_dataset\n",
        "    \n",
        "    print(\"\\nüì¶ Key Dependencies:\")\n",
        "    print(f\"‚Ä¢ Weights & Biases: {wandb.__version__}\")\n",
        "    print(f\"‚Ä¢ Ultralytics: {YOLO.__version__}\")\n",
        "    print(f\"‚Ä¢ Hugging Face Datasets: {datasets.__version__}\")\n",
        "    \n",
        "    print(\"\\n‚úÖ All dependencies verified successfully!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Dependency verification failed: {e}\")\n",
        "    raise  # Re-raise to stop execution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "### 1.4 Initialize W&B\n",
        "Set up Weights & Biases for experiment tracking. We'll use the same project and entity as our local training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize W&B with same project/entity as local training\n",
        "import wandb\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    # Load W&B configuration from improved config\n",
        "    config_path = Path(\"configs/yolov3/improved_config.yaml\")\n",
        "    with open(config_path) as f:\n",
        "        config = yaml.safe_load(f)\n",
        "    \n",
        "    # Initialize W&B run\n",
        "    wandb.init(\n",
        "        project=config['wandb']['project'],\n",
        "        name=config['wandb']['name'],\n",
        "        entity=config['wandb']['entity'],\n",
        "        tags=config['wandb']['tags'],\n",
        "        config=config,\n",
        "        resume=True  # Enable run resumption\n",
        "    )\n",
        "    \n",
        "    print(\"‚úÖ W&B initialized successfully!\")\n",
        "    print(f\"üìä Dashboard: https://wandb.ai/{config['wandb']['entity']}/{config['wandb']['project']}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå W&B initialization failed: {e}\")\n",
        "    raise  # Re-raise to stop execution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 2. Training Preparation\n",
        "\n",
        "### 2.1 Import Source Modules\n",
        "Import our reusable source modules, consistent with how they're used in production scripts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add src to path for module imports (same as scripts)\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/content/pokedex/src')  # For Colab\n",
        "\n",
        "try:\n",
        "    # Import reusable source modules (same as scripts)\n",
        "    from training.yolo.trainer import YOLOTrainer\n",
        "    from evaluation.yolo.evaluator import YOLOEvaluator\n",
        "    \n",
        "    print(\"‚úÖ Source modules imported successfully!\")\n",
        "    print(\"Using same modular architecture as production scripts.\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Module import failed: {e}\")\n",
        "    raise  # Re-raise to stop execution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "### 2.2 Initialize Training\n",
        "Set up the trainer with improved configuration and check for existing checkpoints.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize trainer with improved configuration\n",
        "try:\n",
        "    # Use same configuration as production scripts\n",
        "    config_path = \"configs/yolov3/improved_config.yaml\"\n",
        "    trainer = YOLOTrainer(config_path)\n",
        "    \n",
        "    # Check for existing checkpoints\n",
        "    start_epoch = 0\n",
        "    if os.path.exists(checkpoint_dir):\n",
        "        checkpoint_files = sorted(os.listdir(checkpoint_dir))\n",
        "        if checkpoint_files:\n",
        "            latest_checkpoint = os.path.join(checkpoint_dir, checkpoint_files[-1])\n",
        "            print(f\"\\nüì¶ Found checkpoint: {latest_checkpoint}\")\n",
        "            start_epoch = trainer.load_checkpoint()\n",
        "            print(f\"‚úÖ Resuming from epoch {start_epoch}\")\n",
        "        else:\n",
        "            print(\"\\nüìã No existing checkpoints found. Starting fresh training.\")\n",
        "    \n",
        "    print(\"\\nüéØ Training Configuration:\")\n",
        "    print(f\"‚Ä¢ Config file: {config_path}\")\n",
        "    print(f\"‚Ä¢ Starting epoch: {start_epoch}\")\n",
        "    print(f\"‚Ä¢ Total epochs: {trainer.config['training']['epochs']}\")\n",
        "    print(f\"‚Ä¢ Batch size: {trainer.config['training']['batch_size']}\")\n",
        "    print(f\"‚Ä¢ Learning rate: {trainer.config['training']['learning_rate']}\")\n",
        "    print(f\"‚Ä¢ Checkpoint dir: {checkpoint_dir}\")\n",
        "    \n",
        "    print(\"\\nüìà Improvements over baseline:\")\n",
        "    print(\"‚Ä¢ Enhanced augmentation (rotation, shear, mosaic, mixup)\")\n",
        "    print(\"‚Ä¢ Cosine learning rate scheduling with warmup\")\n",
        "    print(\"‚Ä¢ Early stopping (patience=10)\")\n",
        "    print(\"‚Ä¢ Larger batch size (32 vs 16)\")\n",
        "    print(\"‚Ä¢ Longer training (200 epochs vs 100)\")\n",
        "    print(\"‚Ä¢ Better regularization techniques\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Training initialization failed: {e}\")\n",
        "    raise  # Re-raise to stop execution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 3. Training Execution\n",
        "\n",
        "### 3.1 Execute Training\n",
        "Run the improved training process with proper error handling and progress monitoring.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute improved training with checkpoint support\n",
        "print(\"üöÄ Starting improved training...\")\n",
        "\n",
        "try:\n",
        "    # Start training from last checkpoint or beginning\n",
        "    results = trainer.train(start_epoch=start_epoch)\n",
        "    \n",
        "    print(\"\\n‚úÖ Training completed successfully!\")\n",
        "    print(\"\\nüìä Final Results:\")\n",
        "    for metric, value in results.items():\n",
        "        print(f\"‚Ä¢ {metric}: {value:.4f}\")\n",
        "    \n",
        "    # Save final model to Drive\n",
        "    final_model_path = os.path.join(checkpoint_dir, \"yolov3_improved_final.pt\")\n",
        "    trainer.save_model(final_model_path)\n",
        "    print(f\"\\nüíæ Final model saved: {final_model_path}\")\n",
        "    \n",
        "    # Log final artifacts to W&B\n",
        "    wandb.save(final_model_path)\n",
        "    print(\"\\nüì§ Model artifacts uploaded to W&B\")\n",
        "    \n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n‚ö†Ô∏è Training interrupted by user!\")\n",
        "    print(\"Latest checkpoint was saved automatically.\")\n",
        "    print(\"You can resume training by running this notebook again.\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Training failed: {e}\")\n",
        "    raise  # Re-raise to stop execution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "### 3.2 Evaluate Model & Compare\n",
        "Run evaluation on the test set and compare with baseline results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate improved model and compare with baseline\n",
        "try:\n",
        "    # Initialize evaluator\n",
        "    evaluator = YOLOEvaluator(trainer.model, trainer.config)\n",
        "    \n",
        "    # Run evaluation\n",
        "    test_data = \"liuhuanjim013/pokemon-yolo-1025\"\n",
        "    evaluation_results = evaluator.evaluate_model(test_data)\n",
        "    \n",
        "    print(\"\\nüìä Improved Model Evaluation Results:\")\n",
        "    for metric, value in evaluation_results.items():\n",
        "        print(f\"‚Ä¢ {metric}: {value:.4f}\")\n",
        "    \n",
        "    # Log evaluation results to W&B\n",
        "    wandb.log({\"final_evaluation\": evaluation_results})\n",
        "    \n",
        "    print(\"\\nüìà Improvements Over Baseline:\")\n",
        "    print(\"1. Enhanced Augmentation:\")\n",
        "    print(\"   ‚Ä¢ Added rotation (¬±10¬∞)\")\n",
        "    print(\"   ‚Ä¢ Added translation (¬±20%)\")\n",
        "    print(\"   ‚Ä¢ Added shear (¬±2¬∞)\")\n",
        "    print(\"   ‚Ä¢ Added mosaic (prob=1.0)\")\n",
        "    print(\"   ‚Ä¢ Added mixup (prob=0.1)\")\n",
        "    \n",
        "    print(\"\\n2. Training Enhancements:\")\n",
        "    print(\"   ‚Ä¢ Cosine learning rate scheduling\")\n",
        "    print(\"   ‚Ä¢ 5 epochs warmup\")\n",
        "    print(\"   ‚Ä¢ Early stopping (patience=10)\")\n",
        "    print(\"   ‚Ä¢ Larger batch size (32)\")\n",
        "    print(\"   ‚Ä¢ Longer training (200 epochs)\")\n",
        "    \n",
        "    print(\"\\n3. Expected Benefits:\")\n",
        "    print(\"   ‚Ä¢ Better handling of lighting variations\")\n",
        "    print(\"   ‚Ä¢ Improved size/scale robustness\")\n",
        "    print(\"   ‚Ä¢ Reduced background interference\")\n",
        "    print(\"   ‚Ä¢ Higher overall accuracy\")\n",
        "    print(\"   ‚Ä¢ Better generalization\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Evaluation failed: {e}\")\n",
        "    raise  # Re-raise to stop execution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 4. Cleanup & Next Steps\n",
        "\n",
        "### 4.1 Resource Cleanup\n",
        "Clean up resources and unmount Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean up resources\n",
        "try:\n",
        "    # Finish W&B run\n",
        "    wandb.finish()\n",
        "    print(\"‚úÖ W&B run completed and synced\")\n",
        "    \n",
        "    # Unmount Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.flush_and_unmount()\n",
        "    print(\"‚úÖ Google Drive unmounted safely\")\n",
        "    \n",
        "    print(\"\\nüéØ Next Steps:\")\n",
        "    print(\"1. Check W&B dashboard for training visualizations\")\n",
        "    print(\"2. Review saved checkpoints in Google Drive\")\n",
        "    print(\"3. Compare performance with baseline results\")\n",
        "    print(\"4. Consider further improvements based on results\")\n",
        "    print(\"\\n‚ú® Improved training completed successfully!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Cleanup failed: {e}\")\n",
        "    print(\"‚ö†Ô∏è Please manually unmount Google Drive and close W&B run\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# YOLOv3 Improved Training (Enhanced Parameters)\n",
        "\n",
        "This notebook implements enhanced YOLOv3 training to address original blog limitations.\n",
        "\n",
        "**Goal**: Improve upon baseline with enhanced training parameters.\n",
        "\n",
        "**Dataset**: liuhuanjim013/pokemon-yolo-1025 (1025 classes)\n",
        "\n",
        "**Improvements**: Enhanced augmentation, scheduling, early stopping\n",
        "\n",
        "**Environment Setup**: Uses centralized `setup_environment.py` for consistency with local development.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 1. Environment Setup (Centralized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use centralized environment setup script (consistent with local dev)\n",
        "!python scripts/common/setup_environment.py --experiment yolo --colab\n",
        "\n",
        "print(\"‚úÖ Environment setup completed using centralized script!\")\n",
        "print(\"This ensures consistency with local development environment.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Import Source Modules (Consistent with Scripts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add src to path for module imports (same as scripts)\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/content/pokedex/src')  # For Colab\n",
        "\n",
        "# Import reusable source modules (same as scripts)\n",
        "from training.yolo.trainer import YOLOTrainer\n",
        "\n",
        "print(\"‚úÖ Source modules imported successfully!\")\n",
        "print(\"Using same modular architecture as production scripts.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 3. Initialize Improved Training (Same Logic as Scripts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use same configuration as production scripts\n",
        "config_path = \"configs/yolov3/improved_config.yaml\"\n",
        "\n",
        "# Initialize trainer (same as train_yolov3_improved.py)\n",
        "trainer = YOLOTrainer(config_path)\n",
        "\n",
        "print(\"üöÄ YOLOv3 Improved Training (Enhanced Parameters)\")\n",
        "print(f\"Configuration: {config_path}\")\n",
        "print(\"Goal: Address original blog limitations with enhanced training\")\n",
        "\n",
        "print(\"\\nüìã Improvements over baseline:\")\n",
        "print(\"- Enhanced augmentation (rotation, shear, mosaic, mixup)\")\n",
        "print(\"- Cosine learning rate scheduling with warmup\")\n",
        "print(\"- Early stopping to prevent overfitting\")\n",
        "print(\"- Larger batch size for better gradient estimates\")\n",
        "print(\"- Longer training (200 epochs vs 100)\")\n",
        "print(\"- Better regularization techniques\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Execute Improved Training (Same as Scripts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute improved training (identical logic to train_yolov3_improved.py)\n",
        "print(\"üöÄ Starting improved training...\")\n",
        "\n",
        "try:\n",
        "    # Start training (same enhanced parameters as script)\n",
        "    results = trainer.train()\n",
        "    \n",
        "    print(\"‚úÖ Improved training completed successfully!\")\n",
        "    print(f\"Results: {results}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Improved training failed: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. Evaluation & Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate improved model (same evaluation logic as scripts)\n",
        "test_data = \"liuhuanjim013/pokemon-yolo-1025\"\n",
        "evaluation_results = trainer.evaluate(test_data)\n",
        "\n",
        "print(\"üìä Improved Model Evaluation Results:\")\n",
        "for metric, value in evaluation_results.items():\n",
        "    print(f\"- {metric}: {value:.4f}\")\n",
        "\n",
        "print(\"\\nüìä Comparison with Baseline:\")\n",
        "print(\"\\nBaseline (Original Blog Reproduction):\")\n",
        "print(\"- Epochs: 100\")\n",
        "print(\"- Batch size: 16\")\n",
        "print(\"- Minimal augmentation (only horizontal flip)\")\n",
        "print(\"- No learning rate scheduling\")\n",
        "print(\"- No early stopping\")\n",
        "\n",
        "print(\"\\nImproved (Enhanced Training):\")\n",
        "print(\"- Epochs: 200\")\n",
        "print(\"- Batch size: 32\")\n",
        "print(\"- Enhanced augmentation (rotation, shear, mosaic, mixup)\")\n",
        "print(\"- Cosine learning rate scheduling\")\n",
        "print(\"- Early stopping (patience=10)\")\n",
        "\n",
        "print(\"\\n‚úÖ Improved training completed!\")\n",
        "print(\"Check W&B dashboard for detailed comparison: https://wandb.ai/liuhuanjim013/pokemon-classifier\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# YOLOv3 Improved Training (Enhanced Parameters)\n",
        "\n",
        "This notebook implements enhanced YOLOv3 training to address original blog limitations.\n",
        "\n",
        "**Goal**: Improve upon baseline with enhanced training parameters.\n",
        "\n",
        "**Dataset**: liuhuanjim013/pokemon-yolo-1025 (1025 classes)\n",
        "\n",
        "**Improvements**: Enhanced augmentation, scheduling, early stopping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 1. Environment Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install dependencies\n",
        "!pip install ultralytics wandb datasets huggingface_hub torch torchvision opencv-python pillow matplotlib seaborn pyyaml\n",
        "\n",
        "# Clone repository (if needed)\n",
        "# !git clone https://github.com/your-repo/pokedex.git\n",
        "# %cd pokedex\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Setup W&B\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "# Login to W&B\n",
        "wandb.login()\n",
        "\n",
        "# Initialize experiment\n",
        "wandb.init(\n",
        "    project=\"pokemon-classifier\",\n",
        "    name=\"yolov3-improved-training\",\n",
        "    entity=\"liuhuanjim013\",\n",
        "    config={\n",
        "        \"model\": \"yolov3\",\n",
        "        \"classes\": 1025,\n",
        "        \"dataset\": \"liuhuanjim013/pokemon-yolo-1025\",\n",
        "        \"epochs\": 200,\n",
        "        \"batch_size\": 32,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"scheduler\": \"cosine\",\n",
        "        \"early_stopping\": True,\n",
        "        \"enhanced_augmentation\": True\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 3. Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load dataset from Hugging Face\n",
        "dataset = load_dataset(\"liuhuanjim013/pokemon-yolo-1025\")\n",
        "\n",
        "print(f\"Dataset loaded successfully!\")\n",
        "print(f\"Train split: {len(dataset['train'])} images\")\n",
        "print(f\"Validation split: {len(dataset['validation'])} images\")\n",
        "print(f\"Test split: {len(dataset['test'])} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Improved Training (Enhanced Parameters)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load YOLOv3 model\n",
        "model = YOLO('yolov3.pt')\n",
        "\n",
        "# Configure for 1025 classes\n",
        "model.model.model[-1].nc = 1025\n",
        "\n",
        "print(\"Model configured for 1025 classes\")\n",
        "print(f\"\\nEnhanced training parameters:\")\n",
        "print(f\"- Epochs: 200 (vs 100 in baseline)\")\n",
        "print(f\"- Batch size: 32 (vs 16 in baseline)\")\n",
        "print(f\"- Learning rate: 0.001\")\n",
        "print(f\"- Enhanced augmentation (rotation, shear, mosaic, mixup)\")\n",
        "print(f\"- Cosine learning rate scheduling\")\n",
        "print(f\"- Early stopping (patience=10)\")\n",
        "print(f\"- Better regularization techniques\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train with enhanced parameters\n",
        "results = model.train(\n",
        "    data='liuhuanjim013/pokemon-yolo-1025',\n",
        "    epochs=200,\n",
        "    batch=32,\n",
        "    imgsz=416,\n",
        "    lr0=0.001,\n",
        "    weight_decay=0.0005,\n",
        "    \n",
        "    # Enhanced augmentation to address original limitations\n",
        "    hsv_h=0.015, hsv_s=0.7, hsv_v=0.4,\n",
        "    degrees=10.0,  # Rotation (addresses size sensitivity)\n",
        "    translate=0.2,  # Translation (addresses position sensitivity)\n",
        "    scale=0.9,\n",
        "    shear=2.0,  # Shear (addresses angle sensitivity)\n",
        "    perspective=0.001,\n",
        "    flipud=0.5,\n",
        "    fliplr=0.5,\n",
        "    mosaic=1.0,  # Mosaic (addresses background interference)\n",
        "    mixup=0.1,  # Mixup (improves generalization)\n",
        "    \n",
        "    # Enhanced training\n",
        "    cos_lr=True,  # Cosine learning rate scheduling\n",
        "    warmup_epochs=5,\n",
        "    patience=10,  # Early stopping\n",
        "    \n",
        "    # Save settings\n",
        "    save_period=10,\n",
        "    project='/content/drive/pokemon-yolo-training',\n",
        "    name='yolov3-improved-training'\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Improved training completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. Evaluate Improved Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "val_results = model.val(data='liuhuanjim013/pokemon-yolo-1025')\n",
        "\n",
        "print(\"Improved Model Evaluation Results:\")\n",
        "print(f\"mAP50: {val_results.get('metrics/mAP50(B)', 0):.4f}\")\n",
        "print(f\"mAP50-95: {val_results.get('metrics/mAP50-95(B)', 0):.4f}\")\n",
        "print(f\"Precision: {val_results.get('metrics/precision(B)', 0):.4f}\")\n",
        "print(f\"Recall: {val_results.get('metrics/recall(B)', 0):.4f}\")\n",
        "\n",
        "# Log final metrics to W&B\n",
        "wandb.log({\n",
        "    'final_map50': val_results.get('metrics/mAP50(B)', 0),\n",
        "    'final_map50_95': val_results.get('metrics/mAP50-95(B)', 0),\n",
        "    'final_precision': val_results.get('metrics/precision(B)', 0),\n",
        "    'final_recall': val_results.get('metrics/recall(B)', 0),\n",
        "    'training_completed': True\n",
        "})\n",
        "\n",
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 6. Compare with Baseline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üìä Comparison with Baseline:\")\n",
        "print(\"\\nBaseline (Original Blog Reproduction):\")\n",
        "print(\"- Epochs: 100\")\n",
        "print(\"- Batch size: 16\")\n",
        "print(\"- Minimal augmentation (only horizontal flip)\")\n",
        "print(\"- No learning rate scheduling\")\n",
        "print(\"- No early stopping\")\n",
        "\n",
        "print(\"\\nImproved (Enhanced Training):\")\n",
        "print(\"- Epochs: 200\")\n",
        "print(\"- Batch size: 32\")\n",
        "print(\"- Enhanced augmentation (rotation, shear, mosaic, mixup)\")\n",
        "print(\"- Cosine learning rate scheduling\")\n",
        "print(\"- Early stopping (patience=10)\")\n",
        "\n",
        "print(\"\\n‚úÖ Improved training completed!\")\n",
        "print(\"Check W&B dashboard for detailed comparison.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
